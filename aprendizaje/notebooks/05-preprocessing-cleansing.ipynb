{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#CA3532\"><h1 align=\"left\">Limpieza de datos</h1></font>\n",
    "\n",
    "**Manuel Sánchez-Montañés**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#CA3532\">Limpieza de datos</font>\n",
    "\n",
    "La siguiente etapa del preprocesado es la limpieza de datos, que consiste en las siguientes tareas (entre otras):\n",
    "\n",
    "- Tratamiento de valores ausentes (detección, filtrado, imputación)\n",
    "- Tratamiento de ouliers (o \"valores atípicos\")\n",
    "- Eliminación de información irrelevante (por ejemplo, atributos constantes)\n",
    "- Detección y eliminación de patrones duplicados\n",
    "- Eliminación y/o arreglo de inconsistencias en los datos\n",
    "\n",
    "Primero importaremos las librerías que necesitaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Eliminación de missing values</font>\n",
    "\n",
    "Primero empezaremos con la base de datos \"small.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tc</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1  var2  var3  var4 var5  var6\n",
       "0     1   4.0   NaN   NaN  NaN   NaN\n",
       "1     2   2.0   3.0   NaN  NaN  38.0\n",
       "2     1   2.5   2.5   1.0   tc  39.0\n",
       "3     2   3.5   1.5   0.0   tc  34.0\n",
       "4     2   2.5   2.5   NaN   tc  39.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos:\n",
    "data = pd.read_csv(\"../datasets/small.csv\", na_values = [\"?\", \"none\"], sep = \",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0] # número de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var1    0\n",
       "var2    0\n",
       "var3    1\n",
       "var4    3\n",
       "var5    2\n",
       "var6    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var1     0.0\n",
       "var2     0.0\n",
       "var3    20.0\n",
       "var4    60.0\n",
       "var5    40.0\n",
       "var6    20.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of missing values:\n",
    "100*data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar missing values usaremos el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html#pandas-dataframe-dropna\">pandas.DataFrame.dropna</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1  var2  var3  var4 var5  var6\n",
       "2     1   2.5   2.5   1.0   tc  39.0\n",
       "3     2   3.5   1.5   0.0   tc  34.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar todas las filas que contengan missing values:\n",
    "#data.dropna(inplace=True)\n",
    "# data = data.dropna()\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1  var2\n",
       "0     1   4.0\n",
       "1     2   2.0\n",
       "2     1   2.5\n",
       "3     2   3.5\n",
       "4     2   2.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar todas las columnas que contengan missing values:\n",
    "data.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?data.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tc</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tc</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1  var2  var3  var4 var5  var6\n",
       "1     2   2.0   3.0   NaN  NaN  38.0\n",
       "2     1   2.5   2.5   1.0   tc  39.0\n",
       "3     2   3.5   1.5   0.0   tc  34.0\n",
       "4     2   2.5   2.5   NaN   tc  39.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar todas las filas con menos de 4 NO missing values:\n",
    "data.dropna(thresh = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Imputación de missing values</font>\n",
    "\n",
    "Para imputar missing values usaremos el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html#pandas-dataframe-fillna\">pandas.DataFrame.fillna</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando una constante general:\n",
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {\"madrid\":[1,2,3], \"paris\":3, \"berlin\":\"alemania\"}\n",
    "diccionario[\"paris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando una constante diferente por cada columna:\n",
    "data.fillna({'var3': 0, 'var4': 0, 'var5': 'tc', 'var6': 30.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.loc[:, data.dtypes != object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values usando el valor medio de cada columna (solo para\n",
    "# atributos numéricos):\n",
    "data.fillna(data_num.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1,2,3]\n",
    "tupla = (1,2,3)\n",
    "diccionario = {'spain':'madrid', 'france':'paris',\n",
    "               0:'berlin' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario['spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['var5'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['var5'].mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?data.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values con la el valor medio de cada columna\n",
    "# (para atributos numéricos) y con la moda de cada columna (para atributos\n",
    "# categóricos):\n",
    "data.fillna({'var4': data['var4'].median(),\n",
    "             'var3': data['var3'].mean(),\n",
    "             'var5': data['var5'].mode().iloc[0],\n",
    "             'var6': data['var6'].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Detección de outliers</font>\n",
    "\n",
    "Usaremos el conjunto de datos *labor* para ilustrar el proceso de detección y filtrado de outliers (o \"valores atípicos\"). En las siguientes celdas cargamos los datos y realizamos un preprocesamiento para simplificar el conjunto de datos (solo conservamos los atributos numéricos e imputamos los missing values con la media del atributo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor:\n",
    "data = pd.read_csv(\"../datasets/labor.csv\",\n",
    "                   na_values = [\"?\"], sep = \",\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantener solo los atributos numéricos:\n",
    "data = data.loc[:, data.dtypes != object]\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas de los datos:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de missing values con la media, in place:\n",
    "data.fillna(data.mean(), inplace = True)\n",
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = data[\"shift_diff\"].mean()\n",
    "std   = data[\"shift_diff\"].std()\n",
    "print(\"{} +/- {}\".format(media, 3*std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"shift_diff\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda detecta como outliers a aquellos valores cuya distancia a la media es mayor que 3 veces la desviación estándar. Finalmente muestra la lista de todos los atributos que tienen algún outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.abs(data - data.mean()) > 3.0*data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "is_outlier = np.abs(data - data.mean()) > 3.0*data.std()\n",
    "is_outlier.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier[\"holidays\"].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers:\n",
    "import numpy as np\n",
    "is_outlier = np.abs(data - data.mean()) > 3.0*data.std()\n",
    "for var in data.columns:\n",
    "    print(var, is_outlier[var].any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma de verlo:\n",
    "import numpy as np\n",
    "\n",
    "separacion = np.abs(data - data.mean()) / data.std()\n",
    "is_outlier = separacion > 3\n",
    "#data[is_outlier.any(axis=1)]\n",
    "separacion[is_outlier.any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora miremos con cuidado a las variables *hours*, *stby_pay*, *shift_diff* y *holidays*, todas con outliers. Para cada una de ellas sacaremos por pantalla la media y desviación estándar, mostraremos un histograma, y sacaremos la lista de outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'hours'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de outliers con percentiles:\n",
    "\n",
    "def percentile_outlier_detector(x, threshold=95):\n",
    "    diff = (100 - threshold) / 2\n",
    "    (minval, maxval) = np.percentile(x, [diff, 100 - diff])\n",
    "    return ((x < minval) | (x > maxval))\n",
    "\n",
    "is_outlier2 = percentile_outlier_detector(data[\"hours\"])\n",
    "data[is_outlier2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma: detección de outliers con intercuartiles.\n",
    "\n",
    "<img src=\"../imagenes/IQR.png\" align=\"center\" style=\"float\" width=\"500\">\n",
    "\n",
    "* Calcular el primer y tercer cuartil (Q1 y Q3)\n",
    "* Calcular el IQR (Q3 - Q1)\n",
    "* Considerar outlier todos los puntos que se salgan del rango $[Q1–1.5\\cdot IQR, \\,\\,\\, Q3+1.5 \\cdot IQR]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier_IQR(df):\n",
    "    Q1=df.quantile(0.25)  #unique , duplicates, nan, outliers y transformación logaritmica\n",
    "    Q3=df.quantile(0.75)\n",
    "    IQR = Q3-Q1\n",
    "    return (df<(Q1-1.5*IQR)) | (df>(Q3+1.5*IQR))\n",
    "\n",
    "def transformacion_logaritmica(col):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por intercuartiles:\n",
    "data[is_outlier_IQR(data[\"hours\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"hours\"]].boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(figsize=(10,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'stby_pay'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por intercuartiles:\n",
    "data[is_outlier_IQR(data[var])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'shift_diff'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por intercuartiles:\n",
    "data[is_outlier_IQR(data[var])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'holidays'\n",
    "print(data[var].mean(), data[var].std())\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[is_outlier[var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por intercuartiles:\n",
    "data[is_outlier_IQR(data[var])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Filtrado de outliers</font>\n",
    "\n",
    "La opción más sencilla es eliminar todas las filas que contienen algún valor atípico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de todas las filas que contienen algún valor atípico:\n",
    "data[~is_outlier.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Reemplazamiento de valores atípicos</font>\n",
    "\n",
    "Otra opción es reemplazar los valores atípicos por otro valor. Una opción es la media más / menos tres veces la desviación estándar. En la celda siguiente hacemos esto para la variable *hours*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'holidays'\n",
    "var_mean = data[var].mean()\n",
    "var_std  = data[var].std()\n",
    "print(var_mean, var_std, \"\\n\")\n",
    "print(data[is_outlier[var]])\n",
    "plt.figure()\n",
    "data[var].hist()\n",
    "plt.title(var)\n",
    "data[var][is_outlier[var]] = data[var][is_outlier[var]].clip(var_mean-3*var_std,\n",
    "                                                             var_mean+3*var_std)\n",
    "print(data[is_outlier[var]])\n",
    "plt.figure()\n",
    "data[var].hist()\n",
    "plt.title(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11.094339622641511 + 3*1.2139685648936156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Eliminación de atributos constantes</font>\n",
    "\n",
    "Un atributo cuyo valor es constante para todas las instancias es completamente inútil para cualquier algoritmo de aprendizaje.\n",
    "\n",
    "Volvamos a cargar el conjunto de datos *labor* y lo manipularemos un poco para que tenga atributos constantes e ilustrar este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor:\n",
    "data = pd.read_csv(\"../datasets/labor.csv\", na_values = [\"?\"], sep = \",\")\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pondremos valores constantes a los atributos cola y educ_allw:\n",
    "data[\"cola\"] = 'tc'\n",
    "data[\"educ_allw\"] = 'yes'\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de valores únicos excluyendo NaN:\n",
    "data.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos con un solo valor:\n",
    "data.apply(pd.Series.nunique) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"cola\", \"educ_allw\"], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de eliminar las columnas cola y educ_allw:\n",
    "\n",
    "# del data[\"cola\"]\n",
    "# del data[\"educ_allw\"]\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Detección de duplicados</font>\n",
    "\n",
    "Podemos usar el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html#pandas-dataframe-duplicated\">pandas.DataFrame.duplicated</a> para detectar filas duplicadas en los datos, y el método <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html#pandas-dataframe-drop-duplicates\">pandas.DataFrame.drop_duplicates</a> para eliminar todos los duplicados.\n",
    "\n",
    "Cargaremos de nuevo la base de datos *labor* y la manipularemos un poco para que ahora tenga filas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de datos Labor, mantendremos solo un subconjunto de los atributos:\n",
    "data = pd.read_csv(\"../datasets/labor.csv\", na_values = [\"?\"], sep = \",\")\n",
    "keep_cols = [\"pension\", \"educ_allw\", \"holidays\", \"vacation\"]\n",
    "data = data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = data.iloc[-1:0:-1]\n",
    "aux = data\n",
    "aux[aux.duplicated(keep = 'first')].sort_values(by = [\"pension\", \"educ_allw\",\n",
    "                                   \"holidays\", \"vacation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de duplicados:\n",
    "data[data.duplicated(keep = False)].sort_values(by = [\"pension\", \"educ_allw\",\n",
    "                                                      \"holidays\", \"vacation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de duplicados:\n",
    "data_nodup = data.drop_duplicates()\n",
    "data_nodup.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Otras inconsistencias</font>\n",
    "\n",
    "Podemos detectar muchos más problemas mirando detenidamente a los datos. Algunos ejemplos:\n",
    "\n",
    "- ¿Las fechas parecen fechas?\n",
    "- ¿La edad de una persona está en un rango razonable? \n",
    "- ¿Hay valores \"extraños\" que deberían ser considerados como NaN?\n",
    "- ¿Hay atributos numéricos que deberían ser considerados categóricos?\n",
    "- ¿Hay valores diferentes que se refieren a la misma cosa?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#CA3532\">Ejercicio</font>\n",
    "\n",
    "Carga la base de datos *loan*, explora los datos usando los análisis previos e intenta responder a las cuestiones siguientes:\n",
    "\n",
    "- ¿Hay missing values? Si es así, filtra o imputa estos valores usando la estrategia más apropiada. \n",
    "- ¿Hay outliers? \n",
    "- ¿Hay atributos constantes o instancias duplicadas?\n",
    "- ¿Hay alguna otra inconsistencia en los datos que debería ser corregida?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
